{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GHsssBgWM_l0"
   },
   "source": [
    "# üîç Product Price Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary :\n",
    "---\n",
    "- Parts 1 and 2 : Data Curation & Preprocessing\n",
    "- Parts 3 and 4 : Model Benchmarking ‚Äì Traditional ML vs LLMs\n",
    "- Part 5 : Fine-Tuning GPT-4o Mini\n",
    "- Parts 6 and 7 : Evaluating LLaMA 3.1 8B Quantized\n",
    "- Part 8 : Fine-Tuning LLaMA 3.1 with QLoRA\n",
    "- Part 9 : Evaluating Fine-Tuned LLaMA\n",
    "- Part 10 : Summary & Leaderboard\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Leaderboard\n",
    "\n",
    "| Rank | Model                                   | Avg Error ($)| RMSLE | Accuracy (%) |\n",
    "|:---:|------------------------------------------|----------:|:-----:|-------------:|\n",
    "| ü•á 1 | Finetuned Llama 3.1 8B 4-Bit FT (20K Samples)       | **64.10** | 0.47  | **58.8**    |\n",
    "| 2  | GPT 4O (The Big Guy)                      | 76.42     | 0.86  | 56        |\n",
    "| 3   | GPT 4O Mini                               | 89.73    | 0.63  | 47.6        |\n",
    "| 4  | GPT 4O Mini Fine Tuned                    | 91.45    | 0.68  | 44        |\n",
    "| 5  | Word2Vec + SVM                          | 109.26    | 0.89 | 28.4        |\n",
    "| 6  | BOW + Linear Regression                   | 113.6    | 0.99  | 24.8        |\n",
    "| 7   | Word2Vec + Linear Regression             | 115.14    | 1.05  | 23.6        |\n",
    "| 8  | Human Predictions                         | 126.55    | 1.00  | 32       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ú® Conclusion\n",
    "## ü•á The winner is the LLaMA 3.1 8B (4-bit) fine-tuned on 20K samples \n",
    "\n",
    "LLaMA 3.1 8B (4-bit) fine-tuned on 20K samples outperforms leading frontier model GPT-4o  ‚Äî with the lowest error and highest accuracy (58.8%).\n",
    "\n",
    "Finetuning GPT-4o Mini did not yield any significant improvement in error and accuracy.\n",
    "\n",
    "On the other hand, traditional ML models and even human guesses, gave weaker results and fell behind the top models.\n",
    "\n",
    "üí° Hence we see our **well-tuned open-source small model** can perform even better than leading frontier models when finetuned on a focussed domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì¢ Find more AI related projects on my gihub repo : [GitHub repository](https://github.com/ImonGhosh)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
